{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5tPVJYIpu1I"
      },
      "source": [
        "**This Jupyter Notebook is for training a model to classify different skin conditions across diverse skin tones!**\n",
        "\n",
        " I am using Transfer Learning with EfficientNetB0 because it's already been trained on a large dataset and will help with generalization.\n",
        "\n",
        "The AJL Kaggle competition is centered around AI equity, so I am also incorporating Fairlearn to assess fairness across different Fitzpatrick skin tones.\n",
        "\n",
        "**Learning resources I used during this process included:**\n",
        "\n",
        "FINAL-BT-TransferLearning.ipynb (for transfer learning concepts)\n",
        "\n",
        "FINAL-BT-AlgoFairness.ipynb (for fairness assessment)\n",
        "\n",
        "\"How to do Transfer learning with Efficientnet\" by [DLology](https://www.dlology.com/blog/transfer-learning-with-efficientnet/)\n",
        "\n",
        "This draft was last updated on 02/22/25."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRmuF8GbqhDD",
        "outputId": "f7d4151f-7d69-4d15-ad2c-e0e55c25c4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dzh0fK9wiIA",
        "outputId": "a6ff6631-a376-44b1-862a-c22e1fb36647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to dataset folder in Google Drive\n",
        "dataset_path = \"\"  # Insert your dataset path here. Mine has been removed as I am posting!\n",
        "\n",
        "# List all files\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDSb4Bs25iX1",
        "outputId": "110f435a-d071-4057-f433-c13b959ca132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test.csv', 'sample_submission.csv', 'train.csv', 'test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your file paths here. Mine have been removed as I am posting!\n",
        "train_df = pd.read_csv('')\n",
        "test_df = pd.read_csv('')\n",
        "\n",
        "data_dir = ''\n",
        "test_dir = ''"
      ],
      "metadata": {
        "id": "hDvwCbN38Hai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP4V3MIRpu1M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from fairlearn.metrics import MetricFrame, demographic_parity_difference\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "\n",
        "# Checking if image directories contain files\n",
        "print(\"Training images:\", len(os.listdir(data_dir)))\n",
        "print(\"Test images:\", len(os.listdir(test_dir)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTb4N7dx8SiB",
        "outputId": "2f57b925-4306-4e44-b199-2e703cdd5170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            md5hash  fitzpatrick_scale  fitzpatrick_centaur  \\\n",
            "0  fd06d13de341cc75ad679916c5d7e6a6                  4                    4   \n",
            "1  a4bb4e5206c4e89a303f470576fc5253                  1                    1   \n",
            "2  c94ce27e389f96bda998e7c3fa5c4a2e                  5                    5   \n",
            "3  ebcf2b50dd943c700d4e2b586fcd4425                  3                    3   \n",
            "4  c77d6c895f05fea73a8f3704307036c0                  1                    1   \n",
            "\n",
            "                              label nine_partition_label  \\\n",
            "0                 prurigo-nodularis     benign-epidermal   \n",
            "1  basal-cell-carcinoma-morpheiform  malignant-epidermal   \n",
            "2                            keloid         inflammatory   \n",
            "3              basal-cell-carcinoma  malignant-epidermal   \n",
            "4                 prurigo-nodularis     benign-epidermal   \n",
            "\n",
            "  three_partition_label            qc  ddi_scale  \n",
            "0                benign           NaN         34  \n",
            "1             malignant           NaN         12  \n",
            "2        non-neoplastic  1 Diagnostic         56  \n",
            "3             malignant           NaN         34  \n",
            "4                benign           NaN         12  \n",
            "Training images: 21\n",
            "Test images: 1227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YGXHGy8pu1O"
      },
      "outputs": [],
      "source": [
        "# I need to append '.jpg' to my file names so that they correctly reference the image files\n",
        "# Otherwise, my generator won't find the right images\n",
        "\n",
        "# def add_file_extension(df):\n",
        "#     df['md5hash'] = df['md5hash'].astype(str) + '.jpg'\n",
        "#     return df\n",
        "\n",
        "# File path required changes made change from above code block necessary\n",
        "# def add_file_extension(df):\n",
        "#     df['file_path'] = df['label'] + '/' + df['md5hash'].astype(str) + '.jpg'\n",
        "#     return df\n",
        "\n",
        "# New implemmentation below, forgot test_df does not have a label column\n",
        "def add_file_extension(df, is_test=False):\n",
        "    if is_test:\n",
        "        # Test images are stored directly in the test directory, without label subfolders\n",
        "        df['file_path'] = df['md5hash'].astype(str) + '.jpg'\n",
        "    else:\n",
        "        # Train images are stored inside subfolders named after their labels\n",
        "        df['file_path'] = df['label'] + '/' + df['md5hash'].astype(str) + '.jpg'\n",
        "    return df\n",
        "\n",
        "# Apply the function to both datasets\n",
        "train_df = add_file_extension(train_df, is_test=False)  # Train images in subfolders\n",
        "test_df = add_file_extension(test_df, is_test=True)  # Test images in root directory\n",
        "\n",
        "# Strip whitespace from filenames\n",
        "test_df['file_path'] = test_df['file_path'].apply(lambda x: x.strip())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haHkx2cppu1O"
      },
      "outputs": [],
      "source": [
        "# I need to encode my labels so that my model can work with them\n",
        "# The labels are currently strings (like 'keloid', 'eczema'), so I convert them to numerical values\n",
        "train_df['label_encoded'] = train_df['label'].astype('category').cat.codes\n",
        "label_mapping = dict(enumerate(train_df['label'].astype('category').cat.categories))\n",
        "\n",
        "# I need to split my data so that I have a training set and a validation set\n",
        "# This gives me the ability to check how well my model generalizes\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.2, stratify=train_df['label_encoded'], random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gIMhs21pu1O"
      },
      "outputs": [],
      "source": [
        "# Image Augmentation - I am using this to expand my dataset and prevent overfitting\n",
        "# Referencing: FINAL-BT-DataAugmentation.ipynb\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, horizontal_flip=True, zoom_range=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lUvd6D4pu1P",
        "outputId": "5ee3b1c0-52b6-4705-92c8-1e69b598c008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2288 validated image filenames belonging to 21 classes.\n",
            "Found 572 validated image filenames belonging to 21 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define Paths\n",
        "\n",
        "#converting label col to str\n",
        "train_data['label_encoded'] = train_data['label_encoded'].astype(str)\n",
        "val_data['label_encoded'] = val_data['label_encoded'].astype(str)\n",
        "\n",
        "def create_generator(df, data_gen, batch_size=32, target_size=(128, 128)):\n",
        "    return data_gen.flow_from_dataframe(\n",
        "        df, directory=data_dir,\n",
        "        x_col='file_path', y_col='label_encoded',  # Switched from Kaggle to Google Drive Path bc of upload issues\n",
        "        target_size=target_size, batch_size=batch_size, class_mode='sparse')\n",
        "\n",
        "train_generator = create_generator(train_data, train_datagen)\n",
        "val_generator = create_generator(val_data, val_datagen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BC_WL5cpu1P",
        "outputId": "2a45487d-dd1c-402a-90f1-e28ee1195f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Now I am defining my model\n",
        "# I am using EfficientNetB0 as my base model because it is optimized for performance with fewer parameters\n",
        "# Referencing: FINAL-BT-TransferLearning.ipynb\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Adding layers to fine-tune it for my dataset\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(len(label_mapping), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freezing base model layers. Will prevent initial retraining.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "yQVAhJsTpu1P",
        "outputId": "36a6e145-5555-4b2e-faab-d9bb25395af5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1100s\u001b[0m 15s/step - accuracy: 0.1009 - loss: 2.9829 - val_accuracy: 0.1416 - val_loss: 2.8691\n",
            "Epoch 2/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.1340 - loss: 2.8775 - val_accuracy: 0.1416 - val_loss: 2.8649\n",
            "Epoch 3/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.1348 - loss: 2.9037 - val_accuracy: 0.1416 - val_loss: 2.8611\n",
            "Epoch 4/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.1145 - loss: 2.9129 - val_accuracy: 0.1416 - val_loss: 2.8676\n",
            "Epoch 5/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.1341 - loss: 2.8740 - val_accuracy: 0.1416 - val_loss: 2.8623\n",
            "Epoch 6/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.1346 - loss: 2.8436 - val_accuracy: 0.1416 - val_loss: 2.8717\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-bcbda477f28f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert one-hot to integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \"\"\"\n\u001b[1;32m   1228\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ],
      "source": [
        "# Compiling model with Adam optimizer\n",
        "# Using sparse categorical crossentropy because my labels are integer-encoded\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "# I am using EarlyStopping to prevent overfitting and save time if the model stops improving (efficiency).\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating my model with F1 score since that’s the Kaggle competition metric\n",
        "# val_predictions = model.predict(val_generator)\n",
        "# val_pred_labels = np.argmax(val_predictions, axis=1)\n",
        "# f1 = f1_score(val_data['label_encoded'], val_pred_labels, average='weighted')\n",
        "# print(\"Weighted F1 Score:\", f1)\n",
        "\n",
        "# Got rid of the code block above once I shifted to CoLab\n",
        "\n",
        "# Use validation generator\n",
        "\n",
        "#Erroring\n",
        "  #Resolved error -> converted one hot encoded to int\n",
        "# true_labels = []\n",
        "# for i in range(len(val_generator)):\n",
        "#     batch_labels = val_generator[i][1] #Error\n",
        "#     true_labels.extend(batch_labels)\n",
        "\n",
        "true_labels = []\n",
        "for i in range(len(val_generator)):\n",
        "    batch_labels = np.argmax(val_generator[i][1], axis=1)  # Convert one-hot to integer\n",
        "    true_labels.extend(batch_labels)\n",
        "\n",
        "val_predictions = model.predict(val_generator)\n",
        "val_pred_labels = np.argmax(val_predictions, axis=1)\n",
        "\n",
        "f1 = f1_score(true_labels, val_pred_labels, average='weighted')\n",
        "print(\"Weighted F1 Score:\", f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "gVv2eKmZpu1Q",
        "outputId": "c540ea97-67c8-4f1a-e184-f9036dfecf07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-71c557887992>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  val_data['fitzpatrick_scale'].fillna(\"Unknown\", inplace=True)  # Fill NaN values\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_pred_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-71c557887992>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_pred_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msensitive_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fitzpatrick_scale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_pred_labels' is not defined"
          ]
        }
      ],
      "source": [
        "# Fairness Evaluation\n",
        "# I am using Fairlearn to check for disparities across Fitzpatrick skin tones\n",
        "# Referencing: FINAL-BT-AlgoFairness.ipynb\n",
        "\n",
        "val_data['fitzpatrick_scale'].fillna(\"Unknown\", inplace=True)  # Fill NaN values\n",
        "\n",
        "fairness_metric = MetricFrame(\n",
        "    metrics=f1_score,\n",
        "    y_true=val_data['label_encoded'],\n",
        "    y_pred=val_pred_labels,\n",
        "    sensitive_features=val_data['fitzpatrick_scale']\n",
        ")\n",
        "print(\"Fairness Metrics:\", fairness_metric.by_group)\n",
        "print(\"Demographic Parity Difference:\", demographic_parity_difference(val_data['label_encoded'], val_pred_labels, sensitive_features=val_data['fitzpatrick_scale']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHLQp3sEpu1Q"
      },
      "outputs": [],
      "source": [
        "# Now I generate predictions for Kaggle submission\n",
        "# test_df['file_path'] = test_df['md5hash'].astype(str) + '.jpg'\n",
        "\n",
        "# Remove trailing white spaces etc\n",
        "test_df['file_path'] = test_df['md5hash'].astype(str) + '.jpg'\n",
        "test_df['file_path'] = test_df['file_path'].apply(lambda x: x.strip())  # Remove whitespace issues\n",
        "\n",
        "\n",
        "test_generator = val_datagen.flow_from_dataframe(test_df, directory=test_dir,\n",
        "    x_col='file_path', target_size=(128, 128), batch_size=32,\n",
        "    class_mode=None, shuffle=False)\n",
        "\n",
        "\n",
        "test_predictions = model.predict(test_generator)\n",
        "test_df['label'] = [label_mapping[i] for i in np.argmax(test_predictions, axis=1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX8jo9lapu1Q"
      },
      "outputs": [],
      "source": [
        "# Saving my predictions in the format Kaggle expects\n",
        "test_df[['md5hash', 'label']].to_csv('/content/drive/MyDrive/bttai_kaggle_training_tests/submission.csv', index=False)\n",
        "\n",
        "# Now I can upload 'submission.csv' to Kaggle and check my final weighted F1 score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/skin_condition_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztO-IOPrAMf8",
        "outputId": "d859e160-4972-476c-bee1-04694e4ec04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}